
diff --git a/tutorial/beginner_source/transfer_learning_tutorial.py b/tutorial/beginner_source/transfer_learning_tutorial.py
index a77e61b..755d4d5 100644
--- a/tutorial/beginner_source/transfer_learning_tutorial.py
+++ b/tutorial/beginner_source/transfer_learning_tutorial.py
@@ -1,14 +1,14 @@
 # -*- coding: utf-8 -*-
 """
-Transfer Learning tutorial
+Transfer Learning Tutorial
 ==========================
 **Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_
 
 In this tutorial, you will learn how to train your network using
 transfer learning. You can read more about the transfer learning at `cs231n
-notes <http://cs231n.github.io/transfer-learning/>`__
+notes <https://cs231n.github.io/transfer-learning/>`__
 
-Quoting this notes,
+Quoting these notes,
 
     In practice, very few people train an entire Convolutional Network
     from scratch (with random initialization), because it is relatively
@@ -18,7 +18,7 @@ Quoting this notes,
     ConvNet either as an initialization or a fixed feature extractor for
     the task of interest.
 
-These two major transfer learning scenarios looks as follows:
+These two major transfer learning scenarios look as follows:
 
 -  **Finetuning the convnet**: Instead of random initializaion, we
    initialize the network with a pretrained network, like the one that is
@@ -39,7 +39,6 @@ import torch
 import torch.nn as nn
 import torch.optim as optim
 from torch.optim import lr_scheduler
-from torch.autograd import Variable
 import numpy as np
 import torchvision
 from torchvision import datasets, models, transforms
@@ -75,20 +74,20 @@ plt.ion()   # interactive mode
 # Just normalization for validation
 data_transforms = {
     'train': transforms.Compose([
-        transforms.RandomSizedCrop(224),
+        transforms.RandomResizedCrop(224),
         transforms.RandomHorizontalFlip(),
         transforms.ToTensor(),
         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
     ]),
     'val': transforms.Compose([
-        transforms.Scale(256),
+        transforms.Resize(256),
         transforms.CenterCrop(224),
         transforms.ToTensor(),
         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
     ]),
 }
 
-data_dir = 'hymenoptera_data'
+data_dir = 'data/hymenoptera_data'
 image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                           data_transforms[x])
                   for x in ['train', 'val']}
@@ -98,7 +97,7 @@ dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
 dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
 class_names = image_datasets['train'].classes
 
-use_gpu = torch.cuda.is_available()
+device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
 
 ######################################################################
 # Visualize a few images
@@ -156,44 +155,39 @@ def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
         for phase in ['train', 'val']:
             if phase == 'train':
                 scheduler.step()
-                model.train(True)  # Set model to training mode
+                model.train()  # Set model to training mode
             else:
-                model.train(False)  # Set model to evaluate mode
+                model.eval()   # Set model to evaluate mode
 
             running_loss = 0.0
             running_corrects = 0
 
             # Iterate over data.
-            for data in dataloaders[phase]:
-                # get the inputs
-                inputs, labels = data
-
-                # wrap them in Variable
-                if use_gpu:
-                    inputs = Variable(inputs.cuda())
-                    labels = Variable(labels.cuda())
-                else:
-                    inputs, labels = Variable(inputs), Variable(labels)
+            for inputs, labels in dataloaders[phase]:
+                inputs = inputs.to(device)
+                labels = labels.to(device)
 
                 # zero the parameter gradients
                 optimizer.zero_grad()
 
                 # forward
-                outputs = model(inputs)
-                _, preds = torch.max(outputs.data, 1)
-                loss = criterion(outputs, labels)
+                # track history if only in train
+                with torch.set_grad_enabled(phase == 'train'):
+                    outputs = model(inputs)
+                    _, preds = torch.max(outputs, 1)
+                    loss = criterion(outputs, labels)
 
-                # backward + optimize only if in training phase
-                if phase == 'train':
-                    loss.backward()
-                    optimizer.step()
+                    # backward + optimize only if in training phase
+                    if phase == 'train':
+                        loss.backward()
+                        optimizer.step()
 
                 # statistics
-                running_loss += loss.data[0] * inputs.size(0)
+                running_loss += loss.item() * inputs.size(0)
                 running_corrects += torch.sum(preds == labels.data)
 
             epoch_loss = running_loss / dataset_sizes[phase]
-            epoch_acc = running_corrects / dataset_sizes[phase]
+            epoch_acc = running_corrects.double() / dataset_sizes[phase]
 
             print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                 phase, epoch_loss, epoch_acc))
@@ -223,28 +217,30 @@ def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
 #
 
 def visualize_model(model, num_images=6):
+    was_training = model.training
+    model.eval()
     images_so_far = 0
     fig = plt.figure()
 
-    for i, data in enumerate(dataloaders['val']):
-        inputs, labels = data
-        if use_gpu:
-            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())
-        else:
-            inputs, labels = Variable(inputs), Variable(labels)
+    with torch.no_grad():
+        for i, (inputs, labels) in enumerate(dataloaders['val']):
+            inputs = inputs.to(device)
+            labels = labels.to(device)
 
-        outputs = model(inputs)
-        _, preds = torch.max(outputs.data, 1)
+            outputs = model(inputs)
+            _, preds = torch.max(outputs, 1)
 
-        for j in range(inputs.size()[0]):
-            images_so_far += 1
-            ax = plt.subplot(num_images//2, 2, images_so_far)
-            ax.axis('off')
-            ax.set_title('predicted: {}'.format(class_names[preds[j]]))
-            imshow(inputs.cpu().data[j])
+            for j in range(inputs.size()[0]):
+                images_so_far += 1
+                ax = plt.subplot(num_images//2, 2, images_so_far)
+                ax.axis('off')
+                ax.set_title('predicted: {}'.format(class_names[preds[j]]))
+                imshow(inputs.cpu().data[j])
 
-            if images_so_far == num_images:
-                return
+                if images_so_far == num_images:
+                    model.train(mode=was_training)
+                    return
+        model.train(mode=was_training)
 
 ######################################################################
 # Finetuning the convnet
@@ -257,8 +253,7 @@ model_ft = models.resnet18(pretrained=True)
 num_ftrs = model_ft.fc.in_features
 model_ft.fc = nn.Linear(num_ftrs, 2)
 
-if use_gpu:
-    model_ft = model_ft.cuda()
+model_ft = model_ft.to(device)
 
 criterion = nn.CrossEntropyLoss()
 
@@ -294,7 +289,7 @@ visualize_model(model_ft)
 # gradients are not computed in ``backward()``.
 #
 # You can read more about this in the documentation
-# `here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.
+# `here <https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.
 #
 
 model_conv = torchvision.models.resnet18(pretrained=True)
@@ -305,13 +300,12 @@ for param in model_conv.parameters():
 num_ftrs = model_conv.fc.in_features
 model_conv.fc = nn.Linear(num_ftrs, 2)
 
-if use_gpu:
-    model_conv = model_conv.cuda()
+model_conv = model_conv.to(device)
 
 criterion = nn.CrossEntropyLoss()
 
 # Observe that only parameters of final layer are being optimized as
-# opoosed to before.
+# opposed to before.
 optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)
 
 # Decay LR by a factor of 0.1 every 7 epochs
