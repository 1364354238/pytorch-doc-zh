
diff --git a/tutorial/intermediate_source/char_rnn_classification_tutorial.py b/tutorial/intermediate_source/char_rnn_classification_tutorial.py
index 048a083..cde75e4 100644
--- a/tutorial/intermediate_source/char_rnn_classification_tutorial.py
+++ b/tutorial/intermediate_source/char_rnn_classification_tutorial.py
@@ -32,7 +32,7 @@ spelling:
 I assume you have at least installed PyTorch, know Python, and
 understand Tensors:
 
--  http://pytorch.org/ For installation instructions
+-  https://pytorch.org/ For installation instructions
 -  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general
 -  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview
 -  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user
@@ -40,10 +40,10 @@ understand Tensors:
 It would also be useful to know about RNNs and how they work:
 
 -  `The Unreasonable Effectiveness of Recurrent Neural
-   Networks <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__
+   Networks <https://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__
    shows a bunch of real life examples
 -  `Understanding LSTM
-   Networks <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__
+   Networks <https://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__
    is about LSTMs specifically but also informative about RNNs in
    general
 
@@ -67,6 +67,7 @@ We'll end up with a dictionary of lists of names per language,
 from __future__ import unicode_literals, print_function, division
 from io import open
 import glob
+import os
 
 def findFiles(path): return glob.glob(path)
 
@@ -78,7 +79,7 @@ import string
 all_letters = string.ascii_letters + " .,;'"
 n_letters = len(all_letters)
 
-# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427
+# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427
 def unicodeToAscii(s):
     return ''.join(
         c for c in unicodedata.normalize('NFD', s)
@@ -98,7 +99,7 @@ def readLines(filename):
     return [unicodeToAscii(line) for line in lines]
 
 for filename in findFiles('data/names/*.txt'):
-    category = filename.split('/')[-1].split('.')[0]
+    category = os.path.splitext(os.path.basename(filename))[0]
     all_categories.append(category)
     lines = readLines(filename)
     category_lines[category] = lines
@@ -170,7 +171,7 @@ print(lineToTensor('Jones').size())
 # as regular feed-forward layers.
 #
 # This RNN module (mostly copied from `the PyTorch for Torch users
-# tutorial <http://pytorch.org/tutorials/beginner/former_torchies/
+# tutorial <https://pytorch.org/tutorials/beginner/former_torchies/
 # nn_tutorial.html#example-2-recurrent-net>`__)
 # is just 2 linear layers which operate on an input and hidden state, with
 # a LogSoftmax layer after the output.
@@ -181,7 +182,6 @@ print(lineToTensor('Jones').size())
 #
 
 import torch.nn as nn
-from torch.autograd import Variable
 
 class RNN(nn.Module):
     def __init__(self, input_size, hidden_size, output_size):
@@ -201,7 +201,7 @@ class RNN(nn.Module):
         return output, hidden
 
     def initHidden(self):
-        return Variable(torch.zeros(1, self.hidden_size))
+        return torch.zeros(1, self.hidden_size)
 
 n_hidden = 128
 rnn = RNN(n_letters, n_hidden, n_categories)
@@ -214,12 +214,9 @@ rnn = RNN(n_letters, n_hidden, n_categories)
 # each language) and a next hidden state (which we keep for the next
 # step).
 #
-# Remember that PyTorch modules operate on Variables rather than straight
-# up Tensors.
-#
 
-input = Variable(letterToTensor('A'))
-hidden = Variable(torch.zeros(1, n_hidden))
+input = letterToTensor('A')
+hidden =torch.zeros(1, n_hidden)
 
 output, next_hidden = rnn(input, hidden)
 
@@ -231,8 +228,8 @@ output, next_hidden = rnn(input, hidden)
 # pre-computing batches of Tensors.
 #
 
-input = Variable(lineToTensor('Albert'))
-hidden = Variable(torch.zeros(1, n_hidden))
+input = lineToTensor('Albert')
+hidden = torch.zeros(1, n_hidden)
 
 output, next_hidden = rnn(input[0], hidden)
 print(output)
@@ -258,8 +255,8 @@ print(output)
 #
 
 def categoryFromOutput(output):
-    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data
-    category_i = top_i[0][0]
+    top_n, top_i = output.topk(1)
+    category_i = top_i[0].item()
     return all_categories[category_i], category_i
 
 print(categoryFromOutput(output))
@@ -278,8 +275,8 @@ def randomChoice(l):
 def randomTrainingExample():
     category = randomChoice(all_categories)
     line = randomChoice(category_lines[category])
-    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))
-    line_tensor = Variable(lineToTensor(line))
+    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)
+    line_tensor = lineToTensor(line)
     return category, line, category_tensor, line_tensor
 
 for i in range(10):
@@ -332,7 +329,7 @@ def train(category_tensor, line_tensor):
     for p in rnn.parameters():
         p.data.add_(-learning_rate, p.grad.data)
 
-    return output, loss.data[0]
+    return output, loss.item()
 
 
 ######################################################################
@@ -466,17 +463,18 @@ plt.show()
 
 def predict(input_line, n_predictions=3):
     print('\n> %s' % input_line)
-    output = evaluate(Variable(lineToTensor(input_line)))
-
-    # Get top N categories
-    topv, topi = output.data.topk(n_predictions, 1, True)
-    predictions = []
-
-    for i in range(n_predictions):
-        value = topv[0][i]
-        category_index = topi[0][i]
-        print('(%.2f) %s' % (value, all_categories[category_index]))
-        predictions.append([value, all_categories[category_index]])
+    with torch.no_grad():
+        output = evaluate(lineToTensor(input_line))
+
+        # Get top N categories
+        topv, topi = output.topk(n_predictions, 1, True)
+        predictions = []
+
+        for i in range(n_predictions):
+            value = topv[0][i].item()
+            category_index = topi[0][i].item()
+            print('(%.2f) %s' % (value, all_categories[category_index]))
+            predictions.append([value, all_categories[category_index]])
 
 predict('Dovesky')
 predict('Jackson')
